## NP 문제
### 근사 알고리즘
  - 근사알고리즘 
    - 근사 알고리즘은 근사해를 찾는 대신에 다항식 시간의 복잡도를 가진다
    - 근사 알고리즘은 근사해가 얼마나 최적해에 가까운지를 나타내는 근사비율을 알고리즘과 함께 제시해야함
    - 근사 비율은 근사해의 값과 최적해의 값의 비율로서, 1.0에 가까울수록 정확도가 높은 알고리즘
    - 근사 비율을 계산하려면 최적해를 알아야 하는 모순 발생
    - 최적해를 대신할 수 있는 '간접적인' 최적해를 찾고, 이를 최적해로 삼아서 근사 비율을 계산 
### 여행자 문제(TSP)
   - 조건
      - 도시 A에서 도시 B로 가는 거리는 도시 B에서 도시 A로 가는 거리와 같다(대칭성) - 이 조건은 MST를 사용할때 이렇게하면 쉬우어짐
      - 도시 A에서 도시 B로 가는 거리는 도시 A에서 다른 도시 C를 경유하여 도시 B로 가는 거리보다 짧다(삼각 부등식 특성) - 이 조건은 근사 비율을 구할 때 이렇게 하면 쉬워짐
    - MST는 모든 점을 사이클 없이 연결하는 트리 중에서 트리 간선의 가중치 합이 최소인 트리 (최적의 해보다 더 아래에 있는게 MST)
  - MST를 활용한 근사해 찾는 과정
    - MST를 활용하여 여행자 문제의 근사해를 찾기위해 삼각 부등식 원리를 적용
    - ![image](https://user-images.githubusercontent.com/61530368/173257069-066ffbe8-bdb9-43fc-9c91-9ec2f7eee1fd.png)
  - 알고리즘
    ```
    입력: n개의 도시, 각 도시간의 거리
    출력: 출발 도시에서 각 도시를 1번씩만 방문하고 출발 도시로 돌아오는 도시 순서
    1. 입력에 대하여 MST를 찾는다
    2. MST에서 임의의 도시로부터 출발하여 트리의 간선을 따라서 모든 도시를 방문하고 다시 출발했던 도시로 돌아오는 도시 방문 순서를 찾는다
    3. return 이전 단계에서 찾는 도시 순서에서 중복되어 나타나는 도시를 제거한 도시 순서(단, 도시 순서의 가장 마지막의 출발 도시는 제거하지 않는다)
    ```
    - Line 1
      - 크루스탈 알고리즘: O(mlogm), m은 간선의 수
      - 프림 알고리즘: O(n^2), n은 점의 수
    - Line 2
      - 트리 간선을 따라서 도시 방문 순서를 찾는 데는 O(n) 시간
      - 왜냐하면 트리의 간선 수가 2(n-1)이기 때문
    - Lin2 3
      - 방문 순서를 따라가며 단순히 중복된 도시를 제거하므로 O(n)시간
    - 시간복잡도 : 크루스칼 또는 프림 알고리즘의 시간 복잡도 
  - 근사비율
    - 여행자 문제의 최적해를 실질적으로 알 수 없음
    - 간접적인 최적해인 MST 간선의 가중치의 합(M)을 최적해의 값으로 활용
      - 왜냐하면 실제의 최적해의 값이 M보다 항상 크기 때문
    - Appro_MST_TSP 알고리즘이 계산한 근사해의 값은 2M보다는 크지 않다
      - Line 2에서 MST의 간선을 따라서 도시 방문 순서를 찾을 때 각 간선이 정확히 2번 사용되었으므로 경로의 총 길이는 2M 
      - Line 3에서는 삼각 부등식의 원리를 이용하여 지름길로 도시 방문 순서를 만들기 때문에, 이전 도시 방문 순서에 따른 경로의 길이보다 새로운 도시 방문 순서에 따른 경로의 길이가 더 짧다
    - 따라서 이 알고리즘의 근사비율은 2M/M = 2.0 보다 크지 않다
      - 근사해의 값이 최적해의 값의 2배를 넘지 않는다 
### 정점 커버 문제
  - 정점 커버(Vertex Cover)
    - 주어진 그래프 G=(V, E)에서 각 간선의 양 끝점들중에서 적어도 하나의 끝점을 포함하는 점들의 집합들 중에서 최소 크기의 집합을 찾는 문제
  - 그래프의 모든 간선이 정점 커버에 속한 점에 인전해 있다
    - 정점 커버에 속한 점들로 그래프의 모든 간선을 커버하는 것  
  - 정점커버 예제
    - ![image](https://user-images.githubusercontent.com/61530368/173257876-7facb9fd-a830-4392-8dea-b4f0d8a6d456.png)
    - 위의 그래프에서 {1, 2, 3}, {1, 2}, {1, 3}, {2, 3}, {1}이 각각 정점 커버
    - {2} 또는 {3}은 정점 커버가 아니다 
    - 정점 커버 문제의 해는 {1}  
  - 집합 커버로 해결하기
    - 집합 커버(Set Cover) 문제
      - n개의 원소를 가진 집합 U가 있고,
      - U의 부분집합들을 원소로 하는 집합 F가 주어질 때,
      - F의 원소들인 집합들 중에서 어떤 집합들을 선택하여 합집합하면 U와 가게 되는가?
      - 집합 F에서 서낵하는 집합들의 수를 최소화하는 문제  
    - 정점 커버 문제의 입력 그래프를 집합 커버 문제의 입력으로 변환하여 SetCover 알고리즘으로 해를 찾아서, 그 해를 정점 커버의 해로 삼는다
  - 정점 커버 입력을 집합 커버 입력으로 변환
    - ![image](https://user-images.githubusercontent.com/61530368/173258065-96e11aef-dad2-44f8-a556-3a3c4cfa51b3.png)
  - 집합커버의 근사해 vs 쵲거해
    - ![image](https://user-images.githubusercontent.com/61530368/173258226-c69a5f07-c85d-4594-9c20-65c35e3e587d.png)
    - 집합 커버의 근사 비율은 Klonn
  - 집합 커버보다 작은 근사 비율
    - 선택한 간선(red)의 양 끝점에 인접한 모든 간선(점선)들은 양 끝점에 의해 커버된다
    - ![image](https://user-images.githubusercontent.com/61530368/173258310-60033a33-894c-4924-8b46-051be5e16a5e.png)
  - 극대 매칭
    - 매칭이란 각 간선의 양쪽 끝점들이 중복되지 않는 간선의 집합
    - 극대 매칭은 이미 선택된 간선에 기반을 두고 새로운 간선을 추가하려 해도 더 이상 추가할 수 없는 매칭을 말함
  - 극대 매칭을 이용하여 정점커버를 해결하자
    - 간선의 양 끝점이 이미 커버된 간선의 끝점이 아닐때에만 선택
  - 알고리즘
    ```
    입력: 그래프 G=(V, E)
    출력: 정점 커버
    1. 입력 그래프에서 극대 매칭 M을 찾는다
    2. return 매칭 M의 각선의 양 끝점들의 집합
    ```
  - Approx_Matching_VC
    - G에서 극대 매칭 M으로 간선 a,b,c,d,e,f 선택
    - 근사해는 간선 a, b, c, d, e, f의 양 끝점들
      - 근사해 12개
    - 최적해 7개
    - ![image](https://user-images.githubusercontent.com/61530368/173258550-8fffa883-143d-4055-81ce-db36d815378a.png)
  - 시간복잡도
    - 그래프에서 극대 매칭을 찾는 시간 복잡도와 동일
    - 극대 매칭을 찾기 위해 하나의 간선을 선택할 때
      - 양 끝점이 이미 선택된 간선의 끝점인지를 검사해야하므로 O(n)시간
    - 입력 그래프의 간선 수가 m이면, 각 간선에 대해서 O(n) 시간
    - 시간 복잡도는 O(n) * m = O(nm)  
  - 근사비율
    - 근사 비율을 계산하기 위해서 극대 매칭을 간접적인 최적해로 사용
      - 매칭에 있는 간선의 수를 최적해의 값으로 사용
      - 어떠한 정점 커버라도 극대 매칭에 있는 간선을 커버해야하기 때문
    - Approx_Matching_VC 알고리즘
      - 극대 매칭의 각 간선의 양쪽 끝점들의 집합을 정점 커버의 근사해로서 반환하므로, 근사해의 값은 극대 매칭의 간선수의 2배
      - 근사 비율 = (극대 매칭의 각 간선의 양 끝점들의 수)/(극대 매칭의 간선 수) = 2.0 
  
### 작업 스케줄링 문제
  - n개의 작업의 수행 시간 ti i= 1, ...., n, m개의 동일한 기계가 주어질 때 모든 작업이 가장 빨리 종료되도록 작업을 기계에 배정하는 문제
    - 단, 한 작업은 배정된 기계에서 연속적으로 수행되어야 한다
    - 또한 기계는 한 번에 하나의 작업만을 수행
  - 간단한 답은 그리디 방법으로 작업을 배정
    - 현재까지 배정된 작업에 대해서 가장 빨리 끝나는 기계에 새 작업을 배정 
  - 알고리즘
    ```
    입력: n개의 작업, 각 작업 수행 시간 ti, i = 1, 2,..., n, Mj, j = 1, 2, ..., m
    출력: 모든 작업이 종료된 시간
    1. for j = 1 to m
    2.  L[j] = 0 // L[j] = 기계 Mj에 배정된 마지막 작업의 종료 시간
    3. for i = 1 to n
    4.   min = 1
    5.   for j = 2to m // 가장 일찍 끝나는 기계를 찾기
    6.    if L<j] < L[min]
    7.      min = j
    8.   작업 i를 기계 Mmin에 배정
    9.   L[min] = L[min] + ti
    10. return 가장 늦게 작업 종료 시간
    ```
  - 수행과정
    - 작업의 수행시간이 [5,2,4,3,4,7,9,2,4,1]
    - 4개의 기계
    - ![image](https://user-images.githubusercontent.com/61530368/173259655-a623186b-d317-480d-a5c1-7993d5f7a430.png)
    - ![image](https://user-images.githubusercontent.com/61530368/173259696-6a3aec8c-a1e7-4bc1-80ca-aa4de4d12371.png)
    - 가장 늦게 끝나는 작업의 종류 시간인 13을 리턴
  - 시간 복잡도
    - n개의 작업을 하나씩 가장 빨리 끄나는 기계에 배정
    - 이러한 기계를 찾기 위해 알고리즘 line 5~7의 for~루프가 (m-1)번 수행
    - 모든 기계의 마지막 작업 종료 시간인 L[j]를 살펴보아야하므로 O(m)시간
    - n개의 작업을 배정해야하고,
    - line 10 에서 배열 L을 탐색해야하므로
    - n * O(m) + O(m) = O(nm)
  - 근사 비율
    - OPTo를 최적해의 종료시각이라고 하면
    - 간접적인 최적해 OPT는 다음과 가이 정의 
      - 전체 작업 시간의 합 / m 
    - 작업을 m개의 기계에 동일하게 할당하기는 어려우므로 다음이 성립
      - OPT < OPTo 
    - Approx_JobScheduling알고리즘의 근사해가 OPT'이고, 간접인 최적해가 OPT일때, 다음을 정명
      - OPT' <= 2OPT
    - 마지막으로 배정된 작업 i가 T붜 수행되면, 전체 작업이 T+ti에 종료되므로 OPT' = T + ti 
    - ![image](https://user-images.githubusercontent.com/61530368/173259957-e4f13759-8a96-4b3b-aa0f-fac9bcc8b2a8.png)
  - 근사 비율 계산하기
    - ![image](https://user-images.githubusercontent.com/61530368/173260013-835c7991-e0c0-49cb-b82c-b9aa1f027e40.png)
    - T'는 작업 i를 제외한 모든 작업의 수행 시간의 합을 기계의 수 m으로 나눈 값
      - T'는 작업 i를 제외한 작업들의 평균 종료 시간
    - 그러면 T <= T'이다
      - 작업 i가 배정된 (가장 늦게 끝나는) 기계를 제외한 모든 기계에 배정된 작업은 적어도 T 이후에 종료되기 때문 
    - T와 T'의 관계인, T<=T'를 이용한 OPT' <= 2OPT 증명
      - ![image](https://user-images.githubusercontent.com/61530368/173260141-55d6ea31-e6a7-4506-9a4f-1e49288cefae.png)
### 클러스터링 문제
  - 클러스터링 문제
    - 2차원 평면의 n개의 점들 간의 거리를 고려하여 k개의 그룹으로 나누자
    - ![image](https://user-images.githubusercontent.com/61530368/173260295-2e77c208-704a-4ee2-9069-a02b95a75b93.png)
    - 클러스터링 문제
      - n개의 점을 k개의 그룹으로 나누고 각 그룹의 중심이 되는 k개의 점을 선택하는 문제
      - 단, 가장 큰 반경을 가진 그룹의 직경이 최소가 되도록 k개의 점을 선택해야함 
  - 그리디 방법
    - k개의 센터 선택 방법
      - 1개씩 서낵
      - 임의 점을 첫 번째 센터로 선택
      - ![image](https://user-images.githubusercontent.com/61530368/173260499-0b043a93-0403-4525-845b-33253827dd8c.png)
  - 두 번째 센터는 어느 점이 좋을까
   

 









## 유전 알고리즘
  - 유전자 알고리즘
    - 다윈의 진화론으로부터 창안된 해 탐색 알고리즘 
    - '적자생존'의 개념을 최적화 문제를 해결하는데 적용
  - GA 사이클
    - ![image](https://user-images.githubusercontent.com/61530368/172890504-a56e0714-71dc-4c2d-9e1a-122c3715a8cc.png)
    - 후보해 집합 n개 선택
    - 적합도평가에서 적합도가 높으면 뽑힐 확률이 올라감
    - 후보해 선택에서 m개를 선택(m < n)
    - 교차/돌연변이 연산으로 n개가 다시 만들어짐
    - 최소값 >= 이전 최솟값 중지 (k만큼 기다리게 해서 이전 최솟값 보다 현재 최솟값이 커도 진행하기도함)
  - 슈도코드
    ``` 
      1. 초기후보해 집합 G0을 생성
      2. G0의 각 후보해를 평가
      3. t = 0
      4. repeat
      5.  Gt로부터 Gt+1을 생성 (후보해 선택 및 교치/돌연변이 연산으로 새로운 후보해 생성)
      6.  Gt+1의 각 후보해를 평가 (evaluation)
      7.  t = t + 1
      8. until 종료 조건이 만족될 때까지
      9. return Gt의 후보해 중에서 가장 우수한 해 
    ```
    - 여러 개의 해를 임의로 생성하여 이들을 초기 세대(generation) G0로 놓고
    - repeat-루프에서 현재 세대의 해로부터 다음 세대의 해를 생성해가며
    - 루프가 끝났을 때의 마지막 세대에서 가장 우수한 해를 반환
    - 이 해들은 repeat-루프의 반복적인 수행을 통해서 최적해 또는 최적해에 근접한 해가 될 수 있으므로 후보해라고 부른다
  - 후보해
    - TSP: 5개의 도시(A, B, C, D, E), 시작도시 = A
    - TSP는 시작 도시에서 출발하여 모든 다른 도시를 1번씩만 방문하고 시작 도시로 돌아와야 하므로, ABCDEA, ACDEBA 등이 후보해 
    - ![image](https://user-images.githubusercontent.com/61530368/172892236-1b092096-ba03-4571-895d-809e7198fae0.png)
  - 후보해의 수
    - 시작 도시를 제외한 4개의 도시를 일렬로 나열하는 방법의 수:(5-1)! =4! =24
    - n개의 도시의 후보해 수 = (n-1)!
  - 후보해의 평가
    - ABCDEA의 값 = 5 + 2 + 1+ 3 + 9 = 20
    - ![image](https://user-images.githubusercontent.com/61530368/172892661-3ce0f696-ae2a-45bc-af58-326188022a6f.png)
  - 적합도
    - 후보해의 값 = 후보해의 적합도(Fitness value)
    - 후보해 중에서 최적해의 값에 근접한 적합도를 가진 후보해를 '우수한' 해라고 부른다
  - GA 연산
    - 선택(selection) 연산
      - 현재 세대의 후보해 중에서 우수한 후보해를 선택하는 연산 
      - 현재 세대에 n개의 후보해가 있으면
      - 이렇게 선택된 후보해의 수는 m개로 유지(m < n)
      - 룰렛휠 방법
        - 각 후보해의 적합도에 비례하여 원반의 면적을 할당, 원반을 회전시키면서 원반이 멈추었을 때 핀이 가리키는 후보해를 선택 
        - 적자생존 개념을 모방한 것 면적이 넓은 후보해가 선택될 확률이 높다
        - ![image](https://user-images.githubusercontent.com/61530368/172893579-02d2221d-e092-46df-b1e8-39a38fd87cc1.png)
      - 토너먼트 선택
        - 1. 후보해 집합에서 k개의 후보해를 랜덤하게 선택
        - 2. 선택된 k개 중에서 가장 적합도가 우수한 해를 1개 선택
        - 3. 1~2의 과정을 m개의 우수한 해를 선택할 때까지 반복 
        - 이진 토너먼트 선택 k = 2
    - 교차(crossover) 연산
      - 1-점(point) 교차 연산
        - 랜덤하게 교차할 점을 선태한 후, 두 개의 후보해를 교차점을 기준으로 뒷부분을 서로 교환
        - ![image](https://user-images.githubusercontent.com/61530368/172894139-93ec13ea-9dd8-4e62-b636-1509ffeead93.png)
      - 교차 연산의 목적
        - 선택 연산을 통해서 얻은 우수한 후보해보다 우수한 후보해를 생성하기 위해
      - 교차율(crossover Rate)
        - 문제에 따라 교차 연산을 수행할 후보해의 수를 조절하는데, 이를 교차율이라고 한다
        - 일반적으로 교차율은 0.2 ~ 1.0 번위에서 정한다  

    - 돌연변이 연산 
      - 교차 연산 수행 후에 돌연변이 연산 수행
      - 아주 작은 확률로 후보해의 일부분을 임의로 변형
      - 이 확률을 돌연변이율이라고 하며 일반적으로 (1/PopSize) ~ (1/Length)의 범위에서 사용
        - PopSize란 모집단 크기 (Population Size)로서 한 세대의 후보해의 수 (m)
        - Length란 후보해를 이진 표현으로 했을 경우의 bit 수
      - 돌연변이가 수행된 후에 후보해의 적합도가 오히려 나빠질 수도 있음 
      - ![image](https://user-images.githubusercontent.com/61530368/172894679-56bdc790-c6aa-4c47-b996-ac354ffe8bdf.png)
      - 돌연변이 연산의 목적
        - 다음 세대에 돌연변이가 이루어진 후보해와 다른 후보해를 교차 연산함으로써 이후 세대에서 매우 우수한 후보해를 생성하기 위해
      - 돌연변이 연산 역할
        - 지역최적화에서 글로벌 최적화로 가기위함(나빠질 수도 있음)
        - ![image](https://user-images.githubusercontent.com/61530368/172894963-118e0156-ade1-44e1-8671-6a891652b0d3.png)
  - 종료 조건
    - 유전자 알고리즘이 항상 최적해를 찾는다는 보장이 없기 때문에 종료 조건이 일정하지 않다
      - 일반적으로 알고리즘을 수행시키면서 더 이상 우수한 해가 출현하지 않으면 알고리즘을 종료 
  - GeneticAlgorithm 수행과정
    - 다음의 2차 함수에 대해 유전 알고리즘으로 0 <= x <= 31 구간에서 최대값을 찾아보자 
      - f(X) = -x^2 + 38x + 80
    - 초기 세대를 구성하는 후보해들을 결정
      - 먼저 한 세대의 후보해 수를 4로 정하고, 0~31에서 랜덤하게 4개의 후보해인 1, 29, 3, 10을 선택하였다고 가정
    - 각 후보해의 적합도
      - f(1) = -(1)^2 + 38(1) + 80 = 117
      - f(29) = 341
      - f(3) = 185
      - f(10) = 360  
      - ![image](https://user-images.githubusercontent.com/61530368/173115383-5fd7e0c2-853e-4b09-b03f-31bccf8f08a8.png)
      - 초기 세대의 평균 적합도는 250.75
      - 초기 세대의 평균 적합도와 다음 세대의 평균 적합도를 비교하여 좋아졌는지 나빠졌는지 판단 가능
    - 선택 연산
      - 룰렛 휠 선택 방법으로 후보해 4는 2번 선택 ,후보해 2와 3은 각각 1번 선택, 후보해 1은 선택이 안되었다고 가정
    - 교차 연산
      - 후보해 4가 2개이므로, 후보해 2와 4를 짝짓고, 후보해 3과 4를 짝지어 아래와 아래와 같이 교차 연산을 수행
      - 단, 1점-교차 연산을 위해 아래와 같이 임의의 교차점이 선택되었다고 가정 
    - 돌연변이 연산
      - 교차 연산 후에 후보해 1의 왼쪽에서 두 번째 bit가 돌연변이가 되어 '1'에서 '0'으로 바뀌었다고 가정
      - 다른 후보해는 교차 연산 후와 동일
    - ![image](https://user-images.githubusercontent.com/61530368/173116230-e0c89f61-c5fc-4da8-bb78-8083c0f5765b.png)

    - 두 번째 세대의 후보해에 대한 적합도
      - 평균 적합도가 343.5로 첫 세대의 250.75보다 많이 향상됨
      - ![image](https://user-images.githubusercontent.com/61530368/173116431-63d4078d-aa3a-46e0-9e2e-8a8170d325df.png)
    - 알고리즘 종료
      - 충분한 세대를 거쳐 repeat-루프를 더 수행하여 후보해의 적합도가 변하지 않으면 알고리즘을 종료
      - 후보해 중에서 가장 적합도가 높은 후보해를 리턴
  - TSP를 위한 GeneticAlgorithm
    - 여행자 문제를 해결할 때 GeneticAlgorithm을 적용하기 위해 사용되는 2가지의 교차 연산
      - 2점 교차 연산
      - 사이클 교차 연산 (TSP는 경로자체가 다 나와야하고 한번씩만 나와야하는데 이것때문에 사이클 교차연산을 적용)
    - 여행자 문제의 후보해
      - 시작 도시부터 각 도시를 중복없이 나열하여 만들어진다
    - 2점 교차 연산
      - 임의의 2점을 정한 후, 가운데 부분을 서로 교환
      - 이후 중복되는 도시(점선 박스 내의 도시)를 현재 후보해에 없는 도시로 차례로 바꾼다
      - ![image](https://user-images.githubusercontent.com/61530368/173117607-94632728-c4db-48a2-9cb0-cba3667d853b.png)
      - 후보해 1에 대해 가운데 부분을 제외한 부분에 있는 H, B, A를 각각 C, D, E로 바꾸고
      - 후보해 2에 대해 가운데 부분을 제외한 부분에 있는 C, D, E를 각각 H, B, A로 바꾼다
    - 사이클 교차 연산
      - 후보해 1에서 임의의 도시 C를 선택한 후, C와 같은 위치에 있는 후보해 2의 도시 D와 바꾼다 (1)
      - 바꾼 후에는 후보해 1에는 C가 없고, D가 2개 존재
      - 이를 해결하기 위해 후보해 1에 원래부터 있었던 D를 후보해 2에 D와 같은 위치에 있는 G와 바꾼다 (2)
      - 이렇게 반복하여 C가 후보해 2로부터 후보해 1로 바뀌게 되면 교차 연산을 마친다
      - ![image](https://user-images.githubusercontent.com/61530368/173118439-d2fb674b-b5cc-42ef-a320-f1ac272e6dfb.png)
  - 다양한 실험 필요
    - 유전자 알고리즘은 대부분의 경우 실제로 적지 않은 실험이 필요
    - 주어진 문제에 대해서 모집단의 크기, 교차율, 돌연변이율 등과 같은 파라미터가 다양한 실험을 통해서 조절되어야
    - repeat-루프의 종료 조건도 실험을 통해서 결정할 수밖에 없다
    - 또한 다양한 선택 연산과 교차 연산 중에서 어떤 연산이 주어진 문제에 적절한지도 많은 실험을 통해서 결정해야
  - 유전자 알고리즘 특징
    - 문제의 최적해를 알 수 없고, 기존의 어느 알고리즘으로도 해결하기 어려운 경우에, 최적해에 가까운 해를 찾는데 매우 적절한 알고리즘
    - 유전자 알고리즘이 최적해를 반드시 찾는다는 보장은 없으나 대부분의 경우 매우 우수한 해를 찾는다
    - 반면, 시간이 매우 오래 걸린다

## 모의 담금질 (Simulated Annealing)
  - 모의 담금질 기법
    - 모의 담금질기법은 높은 온도에서 액체 상태인 물질이 온도가 점차 낮아지면서 결정체로 변하는 과정을 모방한 해 탐색 알고리즘 
  - 이웃해
    - 이러한 방식으로 해를 탐색하려면, 후보해에 대해 이웃하는 해(이웃해)를 정의하여야
    - 아래의 오른쪽 그림에서 각 지점은 후보해이고 아래쪽에 위치한 해가 위쪽에 있는 해보다 우수한 해이다.
    - 또한 2개의 후보해 사이의 화살표는 이 후보해들이 서로 이웃하는 관계임을 나타낸다
    - ![image](https://user-images.githubusercontent.com/61530368/173177622-02e1843e-4d4d-462e-ae92-2b8e1179c946.png)
  - 탐색 과정 
    - 높은 T에서의 초기 탐색은 최솟값을 찾는데도 불구하고 확률 개념을 도입하여 현재 해의 이웃해 중에서 현재해보다 "나쁜" 해로 (위 방향으로) 이동하는 자유로움을 보일 수 도 있다
    - T가 낮아지면서 점차 탐색은 아래 방향으로 항햔다
      - T가 낮아질수록 위 방향으로 이동하는 확률이 점차 작아진다
    - 그림에서 처음 도착한 골짜기(지역 최적해, local optimum)에서 더 이상 아래로 탐색할 수 없는 상태에 이르렀을 때 '운 좋게' 위 방향으로 탐색하다가 전역최적(global optimum)를 찾은 것을 보여준다
  - 모의 담금질 기법의 특성
    - 유전자 알고리즘과 마찬가지로 모의 담금질 기법도 항상 전역 최적해를 찾아준다는 보장은 없음
    - 모의 담금질 기법의 또 하나의 특징은 하나의 초기해로부터 탐색이 진행된다는 것 
    - 반면에 유전자 알고리즘은 여러 개의 후보해를 한 세대로 하여 탐색을 수행
  - 알고리즘
    ``` 
    1. 임의의 후보해 s를 선택
    2. 초기 T를 정한다
    3. repeat
    4.  for i = 1 to kt //kt는 T에서의 for-루프 반복 횟수
    5.    s의 이웃해 중에서 랜덤하게 하나의 해 s'를 선택
    6.    d = (s'의 값) - (s의 값)
    7.    if d < 0 //이웃해인 s'가 더 우수한 경우
    8.      s <- s'
    9.      else
    10.       q <- (0, 1)사이에서 램덤하게 선택한 수
    11.       if(p < q) s <- s' // p는 자유롭게 탐색할 확률
    12.  T <- alpha*T //1보다 작은 상수 alpha를 T에 곱하여 새로운 T를 계산
    13. until 종료 조건이 만족될 때까지
    14. return s       
    ```
    - Line 9 ~ 11
      - s'가 s보다 우수하지 않더라도 0~1사이에서 랜덤하게 선택한 수 q가 확률 p보다 작으면, s'가 현재 해인 s가 될 기회를 준다
      - 이 기회가 그림에서 최소값을 찾는데도 불구하고 위쪽에 위치한 이웃해로 탐색을 진행 
      - p는 자유롭게 탐색할 확률 
      - ![image](https://user-images.githubusercontent.com/61530368/173178170-dbf0e46a-2c53-4f0b-9e57-f2304b1367b6.png)
    - Line 12
      - T를 일정한 비율 alpha로 감소시킨다
      - 실제로 0.8 <= alpha <= 0.99 범위에서 미리 정한 냉각율 alpha(cooling ratio)를 T에 곱하여 새로운 T를 계싼
      - 일반적으로 0.99에 가까운 수로 선택 
  - 확률 p 조절
    - 모의 담금질 기법은 T가 높을 때부터 점점 낮아지는 것을 확률 p에 반영시켜서 초기에는 탐색이 자유롭다가 점점 규칙적이 되도록 한다
    - 확률 p는 T에 따라서 변해야함
      - T가 높을 땐, p를 크게 하고
      - T가 0이 되면, p를 0으로 만들어서 나쁜 이웃해 s'가 s가 되지 못하도록 한다
    - s'와 s의 값의 차이 d에 따라 p 조절
      - d 값이 크면, p를 작게 하고
      - d 값이 작으면, p를 크게 한다
    - 이렇게 하는 이유는 값의 차이가 큼에도 불구하고 p를 크게 하면 그 동안 탐색한 결과가 무시되어 랜덤하게 탐색하는 결과를 낳기 때문임  
  - 확률 p
    - 두 가지 요소를 종합한 확률 p 
      - ![image](https://user-images.githubusercontent.com/61530368/173178300-a0f2d7a8-f103-4c4b-80ce-76ace16fc3f8.png)
      - T는 큰 값에서 0까지 변하고, d는 s'와 s의 값의 차이

  - 이웃해 정의
    - TSP의 이웃 해 정의 3가지 예
      - 삽입
      - 교환
      - 반전
  - 삽입
    - 2개의 도시를 랜덤하게 선택한 후에, 두 번째 도시를 첫 번째 옆으로 옮기고, 두 도시 사이의 도시들은 오른쪽으로 1칸씩 이동 
    - 도시 B와 F가 랜덤하게 선택되었다면, F가 B의 바로 오른쪽으로 이동한 후, B와 F사이의 C, D, E를 각각 오른쪽으로 1칸씩 이동  
    - ![image](https://user-images.githubusercontent.com/61530368/173178360-7d751723-00b5-4327-9dae-d515859ba0e7.png)
  - 교환
    - 2개의 도시를 랜덤하게 선택한 후에, 그 도시들의 위치를 서로 바꿈
    - 도시 B와 F가 랜덤하게 선택되었다면, B와 F의 자리를 서로 바꿈
    - ![image](https://user-images.githubusercontent.com/61530368/173178414-a076a700-8d6e-45ea-88f6-f69c7531922a.png)
  - 반전
    - 2개의 도시를 랜덤하게 선택한 후에, 그 두 도시 사이의 도시를 역순으로 만든다. 단, 선택된 두 도시도 반전에 포함시킴
    - 도시 B와 E가 랜덤하게 선택되었다면, [B C D E]가 역순으로 [E D C B]로 바뀜
    - ![image](https://user-images.githubusercontent.com/61530368/173178472-e9de3bbd-eebb-4ad0-bb6d-ed4986b0c89c.png)















